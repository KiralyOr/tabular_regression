{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df: pd.DataFrame, p: float = 0.95, is_train: bool = True ) -> pd.DataFrame:\n",
    "    # Exclude unnecessary columns\n",
    "    df = df.drop(['c2', \n",
    "            'c4', \n",
    "            'appVersion',\n",
    "            'bidFloorPrice'\n",
    "            ], axis=1)\n",
    "    \n",
    "    if is_train:\n",
    "        # filter_outliers\n",
    "        # Calculate the 95th percentile\n",
    "        quantile_p = df['winBid'].quantile(p)\n",
    "\n",
    "        # Filter the DataFrame\n",
    "        df = df[df['winBid'] <= quantile_p]\n",
    "\n",
    "        # Drop rows where countryCode and connectionType are missing\n",
    "        df = df.dropna(subset=['countryCode', 'connectionType'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_engineering(df: pd.DataFrame) -> tuple:\n",
    "\n",
    "    encoders = {}\n",
    "    top_vals = {}\n",
    "\n",
    "    #brandName\n",
    "    # Number of top brands categories to keep\n",
    "    n_brands = 100 \n",
    "    top_N_brands = df['brandName'].value_counts().index[:n_brands]\n",
    "    top_vals['brands'] = top_N_brands\n",
    "    df['brandName'] = np.where(df['brandName'].isin(top_N_brands), df['brandName'], 'Other')\n",
    "    brand_counts = df['brandName'].value_counts().to_dict()\n",
    "    df['brandName_freq'] = df['brandName'].map(brand_counts)\n",
    "    # Drop the original 'brandName' column\n",
    "    df = df.drop('brandName', axis=1)\n",
    "\n",
    "    # bundleId\n",
    "    target_encoder = TargetEncoder(smoothing=0.5)\n",
    "    target_encoder.fit(df['bundleId'], df['winBid'])\n",
    "    encoders['bundleId_encoder'] = target_encoder\n",
    "    df['bundleId_encoded'] = target_encoder.transform(df['bundleId'])\n",
    "    # Drop the original 'bundleId' column\n",
    "    df = df.drop('bundleId', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # countryCode\n",
    "    binary_encoder = BinaryEncoder()\n",
    "    binary_encoder.fit(df['countryCode'])\n",
    "    encoders['countryCode_encoder'] = binary_encoder\n",
    "    df_binary = binary_encoder.transform(df['countryCode'])\n",
    "    # Drop the original 'countryCode' column\n",
    "    df = df.drop('countryCode', axis=1)\n",
    "    # Concatenate the binary encoded 'countryCode' to the original dataframe\n",
    "    df = pd.concat([df, df_binary], axis=1)\n",
    "    df = df.drop('countryCode_0', axis=1)\n",
    "    \n",
    "\n",
    "    # deviceId\n",
    "    device_counts = df['deviceId'].value_counts().to_dict()\n",
    "    df['deviceId_counts'] = df['deviceId'].map(device_counts)\n",
    "    # Drop the original 'deviceId' column\n",
    "    df = df.drop('deviceId', axis=1)\n",
    "\n",
    "\n",
    "    # correctModelName\n",
    "    n_models = 200 \n",
    "    top_N_models = df['correctModelName'].value_counts().index[:n_models]\n",
    "    top_vals['correctModelName'] = top_N_models\n",
    "    df['correctModelName'] = np.where(df['correctModelName'].isin(top_N_models), df['correctModelName'], 'Other')\n",
    "    binary_encoder =  BinaryEncoder()\n",
    "    binary_encoder.fit(df['correctModelName'])\n",
    "    encoders['correctModelName'] = binary_encoder\n",
    "    df_binary = binary_encoder.transform(df['correctModelName'])\n",
    "    # Concatenate the binary encoded 'countryCode' to the original dataframe\n",
    "    df = pd.concat([df, df_binary], axis=1)\n",
    "    # Drop the original 'correctModelName' column\n",
    "    df = df.drop('correctModelName', axis=1)\n",
    "\n",
    "\n",
    "    # eventTimestamp \n",
    "    df['timestamp'] = pd.to_datetime(df['eventTimestamp'], unit='ms')\n",
    "    # Extract date, hour, and day features\n",
    "    df['day_of_month'] = df['timestamp'].dt.day\n",
    "    df['hour'] =df['timestamp'].dt.hour\n",
    "    # Drop the original 'eventTimestamp' and 'timestamp' columns\n",
    "    df = df.drop(['eventTimestamp', 'timestamp'], axis=1)\n",
    "\n",
    "\n",
    "    return  (df, encoders, top_vals)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep(train_data)\n",
    "df, train_encoders, train_top_values = train_feature_engineering(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame, train_encoders, train_top_values, most_frequent_category) -> pd.DataFrame:\n",
    "    #brandName\n",
    "    df['brandName'] = np.where(df['brandName'].isin(train_top_values['brands']), df['brandName'], 'Other')\n",
    "    brand_counts = df['brandName'].value_counts().to_dict()\n",
    "    df['brandName_freq'] = df['brandName'].map(brand_counts)\n",
    "    # Drop the original 'brandName' column\n",
    "    df = df.drop('brandName', axis=1)\n",
    "\n",
    "    # bundleId\n",
    "    target_encoder = train_encoders['bundleId_encoder']\n",
    "    df['bundleId_encoded'] = target_encoder.transform(df['bundleId'])\n",
    "    # Drop the original 'bundleId' column\n",
    "    df = df.drop('bundleId', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # countryCode\n",
    "    binary_encoder = train_encoders['countryCode_encoder']\n",
    "    df_binary = binary_encoder.transform(df['countryCode'])\n",
    "    # Drop the original 'countryCode' column\n",
    "    df = df.drop('countryCode', axis=1)\n",
    "    # Concatenate the binary encoded 'countryCode' to the original dataframe\n",
    "    df = pd.concat([df, df_binary], axis=1)\n",
    "    df = df.drop('countryCode_0', axis=1)\n",
    "    \n",
    "\n",
    "    # deviceId\n",
    "    device_counts = df['deviceId'].value_counts().to_dict()\n",
    "    df['deviceId_counts'] = df['deviceId'].map(device_counts)\n",
    "    # Drop the original 'deviceId' column\n",
    "    df = df.drop('deviceId', axis=1)\n",
    "\n",
    "\n",
    "    # correctModelName\n",
    "    df['correctModelName'] = np.where(df['correctModelName'].isin(train_top_values['correctModelName']), df['correctModelName'], 'Other')\n",
    "    binary_encoder =  train_encoders['correctModelName']\n",
    "    df_binary = binary_encoder.transform(df['correctModelName'])\n",
    "    # Concatenate the binary encoded 'countryCode' to the original dataframe\n",
    "    df = pd.concat([df, df_binary], axis=1)\n",
    "    # Drop the original 'correctModelName' column\n",
    "    df = df.drop('correctModelName', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # eventTimestamp \n",
    "    df['timestamp'] = pd.to_datetime(df['eventTimestamp'], unit='ms')\n",
    "    # Extract date, hour, and day features\n",
    "    df['day_of_month'] = df['timestamp'].dt.day\n",
    "    df['hour'] =df['timestamp'].dt.hour\n",
    "    # Drop the original 'eventTimestamp' and 'timestamp' columns\n",
    "    df = df.drop(['eventTimestamp', 'timestamp'], axis=1)\n",
    "\n",
    "\n",
    "    cat_cols = ['unitDisplayType',\n",
    "                'osAndVersion',\n",
    "                'connectionType',\n",
    "                'c1',\n",
    "                'c3',\n",
    "                'size',\n",
    "                'mediationProviderVersion']\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna(most_frequent_category[col])\n",
    "\n",
    "    \n",
    "    return  df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target\n",
    "target = df['winBid']\n",
    "\n",
    "# Exclude unnecessary columns and the target column\n",
    "features = df.drop(['winBid', \n",
    "                    'has_won'\n",
    "                    ], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_X, val_X, train_y, val_y = train_test_split(features, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unitDisplayType',\n",
       " 'osAndVersion',\n",
       " 'connectionType',\n",
       " 'c1',\n",
       " 'c3',\n",
       " 'size',\n",
       " 'mediationProviderVersion']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical features\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unitDisplayType: 3 unique values\n",
      "osAndVersion: 96 unique values\n",
      "connectionType: 3 unique values\n",
      "c1: 50 unique values\n",
      "c3: 4 unique values\n",
      "size: 6 unique values\n",
      "mediationProviderVersion: 35 unique values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unitDisplayType': 'banner',\n",
       " 'osAndVersion': 'Android-4.0',\n",
       " 'connectionType': 'WIFI',\n",
       " 'c1': '7d3',\n",
       " 'c3': '6b',\n",
       " 'size': '320x50',\n",
       " 'mediationProviderVersion': '11.4.3'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_category = {}\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {train_data[col].nunique()} unique values\")\n",
    "    most_frequent_category[col] = df[col].mode()[0]\n",
    "most_frequent_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_index = [features.columns.get_loc(col) for col in cat_cols]\n",
    "cat_features_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = CatBoostRegressor(iterations=300, learning_rate=0.8, depth=8, loss_function='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03989acabc934fc9911e2a88c529fe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4855870\ttest: 1.4856336\tbest: 1.4856336 (0)\ttotal: 2.3s\tremaining: 11m 28s\n",
      "1:\tlearn: 1.3741421\ttest: 1.3735879\tbest: 1.3735879 (1)\ttotal: 4.17s\tremaining: 10m 21s\n",
      "2:\tlearn: 1.3459697\ttest: 1.3458599\tbest: 1.3458599 (2)\ttotal: 5.9s\tremaining: 9m 44s\n",
      "3:\tlearn: 1.3307930\ttest: 1.3306414\tbest: 1.3306414 (3)\ttotal: 7.6s\tremaining: 9m 22s\n",
      "4:\tlearn: 1.3206179\ttest: 1.3208671\tbest: 1.3208671 (4)\ttotal: 9.14s\tremaining: 8m 59s\n",
      "5:\tlearn: 1.3144299\ttest: 1.3146828\tbest: 1.3146828 (5)\ttotal: 10.6s\tremaining: 8m 37s\n",
      "6:\tlearn: 1.3068110\ttest: 1.3073129\tbest: 1.3073129 (6)\ttotal: 12.2s\tremaining: 8m 30s\n",
      "7:\tlearn: 1.2888506\ttest: 1.2899789\tbest: 1.2899789 (7)\ttotal: 13.9s\tremaining: 8m 26s\n",
      "8:\tlearn: 1.2812649\ttest: 1.2824492\tbest: 1.2824492 (8)\ttotal: 15.6s\tremaining: 8m 25s\n",
      "9:\tlearn: 1.2778757\ttest: 1.2788768\tbest: 1.2788768 (9)\ttotal: 17.5s\tremaining: 8m 26s\n",
      "10:\tlearn: 1.2746062\ttest: 1.2759493\tbest: 1.2759493 (10)\ttotal: 19.4s\tremaining: 8m 28s\n",
      "11:\tlearn: 1.2677861\ttest: 1.2693249\tbest: 1.2693249 (11)\ttotal: 20.9s\tremaining: 8m 21s\n",
      "12:\tlearn: 1.2625432\ttest: 1.2642380\tbest: 1.2642380 (12)\ttotal: 22.4s\tremaining: 8m 14s\n",
      "13:\tlearn: 1.2596270\ttest: 1.2618123\tbest: 1.2618123 (13)\ttotal: 24s\tremaining: 8m 10s\n",
      "14:\tlearn: 1.2578956\ttest: 1.2601161\tbest: 1.2601161 (14)\ttotal: 25.6s\tremaining: 8m 6s\n",
      "15:\tlearn: 1.2558779\ttest: 1.2580255\tbest: 1.2580255 (15)\ttotal: 27.2s\tremaining: 8m 3s\n",
      "16:\tlearn: 1.2526409\ttest: 1.2546645\tbest: 1.2546645 (16)\ttotal: 28.6s\tremaining: 7m 56s\n",
      "17:\tlearn: 1.2506342\ttest: 1.2527008\tbest: 1.2527008 (17)\ttotal: 30s\tremaining: 7m 49s\n",
      "18:\tlearn: 1.2483437\ttest: 1.2505628\tbest: 1.2505628 (18)\ttotal: 31.7s\tremaining: 7m 48s\n",
      "19:\tlearn: 1.2465270\ttest: 1.2487915\tbest: 1.2487915 (19)\ttotal: 33.2s\tremaining: 7m 44s\n",
      "20:\tlearn: 1.2443818\ttest: 1.2467981\tbest: 1.2467981 (20)\ttotal: 34.8s\tremaining: 7m 41s\n",
      "21:\tlearn: 1.2420226\ttest: 1.2442890\tbest: 1.2442890 (21)\ttotal: 36.5s\tremaining: 7m 41s\n",
      "22:\tlearn: 1.2410790\ttest: 1.2435251\tbest: 1.2435251 (22)\ttotal: 38.2s\tremaining: 7m 39s\n",
      "23:\tlearn: 1.2400729\ttest: 1.2426068\tbest: 1.2426068 (23)\ttotal: 39.9s\tremaining: 7m 39s\n",
      "24:\tlearn: 1.2378422\ttest: 1.2405284\tbest: 1.2405284 (24)\ttotal: 41.6s\tremaining: 7m 37s\n",
      "25:\tlearn: 1.2356467\ttest: 1.2385008\tbest: 1.2385008 (25)\ttotal: 43.1s\tremaining: 7m 33s\n",
      "26:\tlearn: 1.2336064\ttest: 1.2365615\tbest: 1.2365615 (26)\ttotal: 44.8s\tremaining: 7m 32s\n",
      "27:\tlearn: 1.2320279\ttest: 1.2349086\tbest: 1.2349086 (27)\ttotal: 46.5s\tremaining: 7m 31s\n",
      "28:\tlearn: 1.2307507\ttest: 1.2336072\tbest: 1.2336072 (28)\ttotal: 48s\tremaining: 7m 28s\n",
      "29:\tlearn: 1.2278745\ttest: 1.2307550\tbest: 1.2307550 (29)\ttotal: 49.5s\tremaining: 7m 25s\n",
      "30:\tlearn: 1.2259015\ttest: 1.2288457\tbest: 1.2288457 (30)\ttotal: 51.1s\tremaining: 7m 23s\n",
      "31:\tlearn: 1.2241320\ttest: 1.2271008\tbest: 1.2271008 (31)\ttotal: 52.7s\tremaining: 7m 21s\n",
      "32:\tlearn: 1.2235328\ttest: 1.2265986\tbest: 1.2265986 (32)\ttotal: 54.3s\tremaining: 7m 19s\n",
      "33:\tlearn: 1.2215913\ttest: 1.2248858\tbest: 1.2248858 (33)\ttotal: 55.5s\tremaining: 7m 14s\n",
      "34:\tlearn: 1.2206270\ttest: 1.2239842\tbest: 1.2239842 (34)\ttotal: 57.2s\tremaining: 7m 12s\n",
      "35:\tlearn: 1.2195467\ttest: 1.2227367\tbest: 1.2227367 (35)\ttotal: 59s\tremaining: 7m 12s\n",
      "36:\tlearn: 1.2179249\ttest: 1.2210619\tbest: 1.2210619 (36)\ttotal: 1m\tremaining: 7m 8s\n",
      "37:\tlearn: 1.2162506\ttest: 1.2194143\tbest: 1.2194143 (37)\ttotal: 1m 1s\tremaining: 7m 6s\n",
      "38:\tlearn: 1.2148298\ttest: 1.2180138\tbest: 1.2180138 (38)\ttotal: 1m 3s\tremaining: 7m 2s\n",
      "39:\tlearn: 1.2139097\ttest: 1.2172155\tbest: 1.2172155 (39)\ttotal: 1m 4s\tremaining: 7m 1s\n",
      "40:\tlearn: 1.2127617\ttest: 1.2161019\tbest: 1.2161019 (40)\ttotal: 1m 6s\tremaining: 6m 59s\n",
      "41:\tlearn: 1.2111240\ttest: 1.2145578\tbest: 1.2145578 (41)\ttotal: 1m 7s\tremaining: 6m 56s\n",
      "42:\tlearn: 1.2097876\ttest: 1.2131708\tbest: 1.2131708 (42)\ttotal: 1m 10s\tremaining: 7m\n",
      "43:\tlearn: 1.2082893\ttest: 1.2117119\tbest: 1.2117119 (43)\ttotal: 1m 13s\tremaining: 7m 5s\n",
      "44:\tlearn: 1.2077890\ttest: 1.2113871\tbest: 1.2113871 (44)\ttotal: 1m 15s\tremaining: 7m 5s\n",
      "45:\tlearn: 1.2062808\ttest: 1.2099290\tbest: 1.2099290 (45)\ttotal: 1m 16s\tremaining: 7m 4s\n",
      "46:\tlearn: 1.2052583\ttest: 1.2090126\tbest: 1.2090126 (46)\ttotal: 1m 18s\tremaining: 7m 2s\n",
      "47:\tlearn: 1.2038896\ttest: 1.2077379\tbest: 1.2077379 (47)\ttotal: 1m 20s\tremaining: 7m\n",
      "48:\tlearn: 1.2026770\ttest: 1.2065224\tbest: 1.2065224 (48)\ttotal: 1m 21s\tremaining: 6m 59s\n",
      "49:\tlearn: 1.2014165\ttest: 1.2052595\tbest: 1.2052595 (49)\ttotal: 1m 23s\tremaining: 6m 57s\n",
      "50:\tlearn: 1.1993376\ttest: 1.2035212\tbest: 1.2035212 (50)\ttotal: 1m 25s\tremaining: 6m 56s\n",
      "51:\tlearn: 1.1981067\ttest: 1.2024142\tbest: 1.2024142 (51)\ttotal: 1m 26s\tremaining: 6m 54s\n",
      "52:\tlearn: 1.1968685\ttest: 1.2011129\tbest: 1.2011129 (52)\ttotal: 1m 28s\tremaining: 6m 51s\n",
      "53:\tlearn: 1.1952051\ttest: 1.1994539\tbest: 1.1994539 (53)\ttotal: 1m 29s\tremaining: 6m 49s\n",
      "54:\tlearn: 1.1936080\ttest: 1.1982589\tbest: 1.1982589 (54)\ttotal: 1m 31s\tremaining: 6m 45s\n",
      "55:\tlearn: 1.1925203\ttest: 1.1972798\tbest: 1.1972798 (55)\ttotal: 1m 32s\tremaining: 6m 43s\n",
      "56:\tlearn: 1.1912952\ttest: 1.1962718\tbest: 1.1962718 (56)\ttotal: 1m 33s\tremaining: 6m 40s\n",
      "57:\tlearn: 1.1904886\ttest: 1.1955340\tbest: 1.1955340 (57)\ttotal: 1m 35s\tremaining: 6m 39s\n",
      "58:\tlearn: 1.1883620\ttest: 1.1935351\tbest: 1.1935351 (58)\ttotal: 1m 36s\tremaining: 6m 36s\n",
      "59:\tlearn: 1.1879706\ttest: 1.1931858\tbest: 1.1931858 (59)\ttotal: 1m 38s\tremaining: 6m 32s\n",
      "60:\tlearn: 1.1871725\ttest: 1.1924063\tbest: 1.1924063 (60)\ttotal: 1m 39s\tremaining: 6m 30s\n",
      "61:\tlearn: 1.1866657\ttest: 1.1919478\tbest: 1.1919478 (61)\ttotal: 1m 41s\tremaining: 6m 29s\n",
      "62:\tlearn: 1.1857520\ttest: 1.1909935\tbest: 1.1909935 (62)\ttotal: 1m 42s\tremaining: 6m 26s\n",
      "63:\tlearn: 1.1849497\ttest: 1.1902722\tbest: 1.1902722 (63)\ttotal: 1m 44s\tremaining: 6m 24s\n",
      "64:\tlearn: 1.1836381\ttest: 1.1892025\tbest: 1.1892025 (64)\ttotal: 1m 45s\tremaining: 6m 22s\n",
      "65:\tlearn: 1.1827954\ttest: 1.1884056\tbest: 1.1884056 (65)\ttotal: 1m 47s\tremaining: 6m 20s\n",
      "66:\tlearn: 1.1822335\ttest: 1.1878891\tbest: 1.1878891 (66)\ttotal: 1m 48s\tremaining: 6m 19s\n",
      "67:\tlearn: 1.1809720\ttest: 1.1866783\tbest: 1.1866783 (67)\ttotal: 1m 50s\tremaining: 6m 17s\n",
      "68:\tlearn: 1.1798884\ttest: 1.1856642\tbest: 1.1856642 (68)\ttotal: 1m 52s\tremaining: 6m 15s\n",
      "69:\tlearn: 1.1792451\ttest: 1.1852286\tbest: 1.1852286 (69)\ttotal: 1m 54s\tremaining: 6m 15s\n",
      "70:\tlearn: 1.1781281\ttest: 1.1839192\tbest: 1.1839192 (70)\ttotal: 1m 55s\tremaining: 6m 13s\n",
      "71:\tlearn: 1.1767065\ttest: 1.1826059\tbest: 1.1826059 (71)\ttotal: 1m 57s\tremaining: 6m 11s\n",
      "72:\tlearn: 1.1746390\ttest: 1.1808031\tbest: 1.1808031 (72)\ttotal: 1m 58s\tremaining: 6m 8s\n",
      "73:\tlearn: 1.1739888\ttest: 1.1802733\tbest: 1.1802733 (73)\ttotal: 2m\tremaining: 6m 6s\n",
      "74:\tlearn: 1.1729710\ttest: 1.1792516\tbest: 1.1792516 (74)\ttotal: 2m 1s\tremaining: 6m 5s\n",
      "75:\tlearn: 1.1723359\ttest: 1.1787146\tbest: 1.1787146 (75)\ttotal: 2m 3s\tremaining: 6m 4s\n",
      "76:\tlearn: 1.1720484\ttest: 1.1785161\tbest: 1.1785161 (76)\ttotal: 2m 4s\tremaining: 6m 1s\n",
      "77:\tlearn: 1.1715420\ttest: 1.1780882\tbest: 1.1780882 (77)\ttotal: 2m 6s\tremaining: 5m 59s\n",
      "78:\tlearn: 1.1705096\ttest: 1.1771614\tbest: 1.1771614 (78)\ttotal: 2m 7s\tremaining: 5m 56s\n",
      "79:\tlearn: 1.1700280\ttest: 1.1766962\tbest: 1.1766962 (79)\ttotal: 2m 9s\tremaining: 5m 54s\n",
      "80:\tlearn: 1.1693146\ttest: 1.1758761\tbest: 1.1758761 (80)\ttotal: 2m 10s\tremaining: 5m 53s\n",
      "81:\tlearn: 1.1684769\ttest: 1.1752988\tbest: 1.1752988 (81)\ttotal: 2m 11s\tremaining: 5m 50s\n",
      "82:\tlearn: 1.1672560\ttest: 1.1741386\tbest: 1.1741386 (82)\ttotal: 2m 13s\tremaining: 5m 49s\n",
      "83:\tlearn: 1.1667128\ttest: 1.1737044\tbest: 1.1737044 (83)\ttotal: 2m 15s\tremaining: 5m 48s\n",
      "84:\tlearn: 1.1657569\ttest: 1.1727088\tbest: 1.1727088 (84)\ttotal: 2m 16s\tremaining: 5m 46s\n",
      "85:\tlearn: 1.1653272\ttest: 1.1724035\tbest: 1.1724035 (85)\ttotal: 2m 18s\tremaining: 5m 44s\n",
      "86:\tlearn: 1.1646946\ttest: 1.1718273\tbest: 1.1718273 (86)\ttotal: 2m 19s\tremaining: 5m 42s\n",
      "87:\tlearn: 1.1635276\ttest: 1.1707742\tbest: 1.1707742 (87)\ttotal: 2m 21s\tremaining: 5m 40s\n",
      "88:\tlearn: 1.1628131\ttest: 1.1702175\tbest: 1.1702175 (88)\ttotal: 2m 22s\tremaining: 5m 38s\n",
      "89:\tlearn: 1.1617068\ttest: 1.1690467\tbest: 1.1690467 (89)\ttotal: 2m 24s\tremaining: 5m 37s\n",
      "90:\tlearn: 1.1609205\ttest: 1.1682778\tbest: 1.1682778 (90)\ttotal: 2m 25s\tremaining: 5m 34s\n",
      "91:\tlearn: 1.1603296\ttest: 1.1678044\tbest: 1.1678044 (91)\ttotal: 2m 27s\tremaining: 5m 32s\n",
      "92:\tlearn: 1.1598077\ttest: 1.1672545\tbest: 1.1672545 (92)\ttotal: 2m 28s\tremaining: 5m 31s\n",
      "93:\tlearn: 1.1593284\ttest: 1.1667648\tbest: 1.1667648 (93)\ttotal: 2m 30s\tremaining: 5m 29s\n",
      "94:\tlearn: 1.1590469\ttest: 1.1664558\tbest: 1.1664558 (94)\ttotal: 2m 31s\tremaining: 5m 27s\n",
      "95:\tlearn: 1.1582256\ttest: 1.1656625\tbest: 1.1656625 (95)\ttotal: 2m 33s\tremaining: 5m 26s\n",
      "96:\tlearn: 1.1577785\ttest: 1.1652517\tbest: 1.1652517 (96)\ttotal: 2m 35s\tremaining: 5m 24s\n",
      "97:\tlearn: 1.1572340\ttest: 1.1647914\tbest: 1.1647914 (97)\ttotal: 2m 36s\tremaining: 5m 23s\n",
      "98:\tlearn: 1.1567763\ttest: 1.1643755\tbest: 1.1643755 (98)\ttotal: 2m 38s\tremaining: 5m 21s\n",
      "99:\tlearn: 1.1564424\ttest: 1.1640742\tbest: 1.1640742 (99)\ttotal: 2m 39s\tremaining: 5m 19s\n",
      "100:\tlearn: 1.1557047\ttest: 1.1634836\tbest: 1.1634836 (100)\ttotal: 2m 41s\tremaining: 5m 17s\n",
      "101:\tlearn: 1.1547793\ttest: 1.1625811\tbest: 1.1625811 (101)\ttotal: 2m 42s\tremaining: 5m 15s\n",
      "102:\tlearn: 1.1544508\ttest: 1.1622744\tbest: 1.1622744 (102)\ttotal: 2m 44s\tremaining: 5m 14s\n",
      "103:\tlearn: 1.1536636\ttest: 1.1616010\tbest: 1.1616010 (103)\ttotal: 2m 46s\tremaining: 5m 13s\n",
      "104:\tlearn: 1.1533471\ttest: 1.1612697\tbest: 1.1612697 (104)\ttotal: 2m 49s\tremaining: 5m 14s\n",
      "105:\tlearn: 1.1525505\ttest: 1.1606393\tbest: 1.1606393 (105)\ttotal: 2m 50s\tremaining: 5m 12s\n",
      "106:\tlearn: 1.1523866\ttest: 1.1605156\tbest: 1.1605156 (106)\ttotal: 2m 52s\tremaining: 5m 11s\n",
      "107:\tlearn: 1.1512290\ttest: 1.1596035\tbest: 1.1596035 (107)\ttotal: 2m 54s\tremaining: 5m 10s\n",
      "108:\tlearn: 1.1507648\ttest: 1.1591267\tbest: 1.1591267 (108)\ttotal: 2m 55s\tremaining: 5m 8s\n",
      "109:\tlearn: 1.1502871\ttest: 1.1586768\tbest: 1.1586768 (109)\ttotal: 2m 57s\tremaining: 5m 6s\n",
      "110:\tlearn: 1.1498349\ttest: 1.1583275\tbest: 1.1583275 (110)\ttotal: 2m 58s\tremaining: 5m 4s\n",
      "111:\tlearn: 1.1490714\ttest: 1.1574625\tbest: 1.1574625 (111)\ttotal: 3m\tremaining: 5m 2s\n",
      "112:\tlearn: 1.1483145\ttest: 1.1567021\tbest: 1.1567021 (112)\ttotal: 3m 1s\tremaining: 5m\n",
      "113:\tlearn: 1.1474293\ttest: 1.1558334\tbest: 1.1558334 (113)\ttotal: 3m 3s\tremaining: 4m 59s\n",
      "114:\tlearn: 1.1469967\ttest: 1.1553849\tbest: 1.1553849 (114)\ttotal: 3m 4s\tremaining: 4m 57s\n",
      "115:\tlearn: 1.1461165\ttest: 1.1546026\tbest: 1.1546026 (115)\ttotal: 3m 6s\tremaining: 4m 55s\n",
      "116:\tlearn: 1.1449544\ttest: 1.1535744\tbest: 1.1535744 (116)\ttotal: 3m 7s\tremaining: 4m 53s\n",
      "117:\tlearn: 1.1440669\ttest: 1.1528053\tbest: 1.1528053 (117)\ttotal: 3m 9s\tremaining: 4m 51s\n",
      "118:\tlearn: 1.1436510\ttest: 1.1523690\tbest: 1.1523690 (118)\ttotal: 3m 10s\tremaining: 4m 50s\n",
      "119:\tlearn: 1.1431084\ttest: 1.1519147\tbest: 1.1519147 (119)\ttotal: 3m 12s\tremaining: 4m 48s\n",
      "120:\tlearn: 1.1428683\ttest: 1.1517522\tbest: 1.1517522 (120)\ttotal: 3m 13s\tremaining: 4m 46s\n",
      "121:\tlearn: 1.1423340\ttest: 1.1513424\tbest: 1.1513424 (121)\ttotal: 3m 14s\tremaining: 4m 44s\n",
      "122:\tlearn: 1.1419359\ttest: 1.1510565\tbest: 1.1510565 (122)\ttotal: 3m 16s\tremaining: 4m 43s\n",
      "123:\tlearn: 1.1415619\ttest: 1.1507802\tbest: 1.1507802 (123)\ttotal: 3m 18s\tremaining: 4m 41s\n",
      "124:\tlearn: 1.1412132\ttest: 1.1504443\tbest: 1.1504443 (124)\ttotal: 3m 20s\tremaining: 4m 40s\n",
      "125:\tlearn: 1.1408829\ttest: 1.1501570\tbest: 1.1501570 (125)\ttotal: 3m 21s\tremaining: 4m 38s\n",
      "126:\tlearn: 1.1401388\ttest: 1.1493497\tbest: 1.1493497 (126)\ttotal: 3m 23s\tremaining: 4m 36s\n",
      "127:\tlearn: 1.1395387\ttest: 1.1488879\tbest: 1.1488879 (127)\ttotal: 3m 24s\tremaining: 4m 35s\n",
      "128:\tlearn: 1.1391476\ttest: 1.1486075\tbest: 1.1486075 (128)\ttotal: 3m 26s\tremaining: 4m 33s\n",
      "129:\tlearn: 1.1386184\ttest: 1.1481260\tbest: 1.1481260 (129)\ttotal: 3m 27s\tremaining: 4m 31s\n",
      "130:\tlearn: 1.1382615\ttest: 1.1477825\tbest: 1.1477825 (130)\ttotal: 3m 29s\tremaining: 4m 30s\n",
      "131:\tlearn: 1.1379497\ttest: 1.1475499\tbest: 1.1475499 (131)\ttotal: 3m 31s\tremaining: 4m 29s\n",
      "132:\tlearn: 1.1374587\ttest: 1.1470337\tbest: 1.1470337 (132)\ttotal: 3m 33s\tremaining: 4m 28s\n",
      "133:\tlearn: 1.1369373\ttest: 1.1464984\tbest: 1.1464984 (133)\ttotal: 3m 35s\tremaining: 4m 27s\n",
      "134:\tlearn: 1.1363596\ttest: 1.1458837\tbest: 1.1458837 (134)\ttotal: 3m 37s\tremaining: 4m 25s\n",
      "135:\tlearn: 1.1359170\ttest: 1.1454496\tbest: 1.1454496 (135)\ttotal: 3m 39s\tremaining: 4m 24s\n",
      "136:\tlearn: 1.1356335\ttest: 1.1452560\tbest: 1.1452560 (136)\ttotal: 3m 40s\tremaining: 4m 22s\n",
      "137:\tlearn: 1.1347721\ttest: 1.1444070\tbest: 1.1444070 (137)\ttotal: 3m 42s\tremaining: 4m 21s\n",
      "138:\tlearn: 1.1344449\ttest: 1.1441687\tbest: 1.1441687 (138)\ttotal: 3m 44s\tremaining: 4m 19s\n",
      "139:\tlearn: 1.1337844\ttest: 1.1436206\tbest: 1.1436206 (139)\ttotal: 3m 45s\tremaining: 4m 18s\n",
      "140:\tlearn: 1.1333155\ttest: 1.1432017\tbest: 1.1432017 (140)\ttotal: 3m 47s\tremaining: 4m 16s\n",
      "141:\tlearn: 1.1330206\ttest: 1.1429459\tbest: 1.1429459 (141)\ttotal: 3m 48s\tremaining: 4m 14s\n",
      "142:\tlearn: 1.1323713\ttest: 1.1423388\tbest: 1.1423388 (142)\ttotal: 3m 50s\tremaining: 4m 12s\n",
      "143:\tlearn: 1.1317713\ttest: 1.1416657\tbest: 1.1416657 (143)\ttotal: 3m 51s\tremaining: 4m 11s\n",
      "144:\tlearn: 1.1313887\ttest: 1.1412968\tbest: 1.1412968 (144)\ttotal: 3m 53s\tremaining: 4m 9s\n",
      "145:\tlearn: 1.1308464\ttest: 1.1407600\tbest: 1.1407600 (145)\ttotal: 3m 55s\tremaining: 4m 8s\n",
      "146:\tlearn: 1.1304848\ttest: 1.1404827\tbest: 1.1404827 (146)\ttotal: 3m 57s\tremaining: 4m 6s\n",
      "147:\tlearn: 1.1301422\ttest: 1.1401839\tbest: 1.1401839 (147)\ttotal: 3m 58s\tremaining: 4m 5s\n",
      "148:\tlearn: 1.1295310\ttest: 1.1397115\tbest: 1.1397115 (148)\ttotal: 4m\tremaining: 4m 4s\n",
      "149:\tlearn: 1.1293888\ttest: 1.1396219\tbest: 1.1396219 (149)\ttotal: 4m 3s\tremaining: 4m 3s\n",
      "150:\tlearn: 1.1291846\ttest: 1.1395521\tbest: 1.1395521 (150)\ttotal: 4m 4s\tremaining: 4m 1s\n",
      "151:\tlearn: 1.1288824\ttest: 1.1394077\tbest: 1.1394077 (151)\ttotal: 4m 6s\tremaining: 3m 59s\n",
      "152:\tlearn: 1.1286102\ttest: 1.1391377\tbest: 1.1391377 (152)\ttotal: 4m 8s\tremaining: 3m 58s\n",
      "153:\tlearn: 1.1282082\ttest: 1.1388157\tbest: 1.1388157 (153)\ttotal: 4m 10s\tremaining: 3m 57s\n",
      "154:\tlearn: 1.1278256\ttest: 1.1385989\tbest: 1.1385989 (154)\ttotal: 4m 11s\tremaining: 3m 55s\n",
      "155:\tlearn: 1.1276472\ttest: 1.1385412\tbest: 1.1385412 (155)\ttotal: 4m 13s\tremaining: 3m 54s\n",
      "156:\tlearn: 1.1273570\ttest: 1.1383383\tbest: 1.1383383 (156)\ttotal: 4m 14s\tremaining: 3m 52s\n",
      "157:\tlearn: 1.1269592\ttest: 1.1379185\tbest: 1.1379185 (157)\ttotal: 4m 16s\tremaining: 3m 50s\n",
      "158:\tlearn: 1.1266185\ttest: 1.1376603\tbest: 1.1376603 (158)\ttotal: 4m 18s\tremaining: 3m 48s\n",
      "159:\tlearn: 1.1262204\ttest: 1.1373028\tbest: 1.1373028 (159)\ttotal: 4m 19s\tremaining: 3m 47s\n",
      "160:\tlearn: 1.1260479\ttest: 1.1371854\tbest: 1.1371854 (160)\ttotal: 4m 21s\tremaining: 3m 45s\n",
      "161:\tlearn: 1.1256404\ttest: 1.1368119\tbest: 1.1368119 (161)\ttotal: 4m 23s\tremaining: 3m 44s\n",
      "162:\tlearn: 1.1253614\ttest: 1.1365319\tbest: 1.1365319 (162)\ttotal: 4m 25s\tremaining: 3m 42s\n",
      "163:\tlearn: 1.1245417\ttest: 1.1357186\tbest: 1.1357186 (163)\ttotal: 4m 26s\tremaining: 3m 40s\n",
      "164:\tlearn: 1.1242083\ttest: 1.1354656\tbest: 1.1354656 (164)\ttotal: 4m 28s\tremaining: 3m 39s\n",
      "165:\tlearn: 1.1238423\ttest: 1.1351794\tbest: 1.1351794 (165)\ttotal: 4m 29s\tremaining: 3m 37s\n",
      "166:\tlearn: 1.1234159\ttest: 1.1347588\tbest: 1.1347588 (166)\ttotal: 4m 31s\tremaining: 3m 36s\n",
      "167:\tlearn: 1.1229792\ttest: 1.1343567\tbest: 1.1343567 (167)\ttotal: 4m 32s\tremaining: 3m 34s\n",
      "168:\tlearn: 1.1225319\ttest: 1.1339617\tbest: 1.1339617 (168)\ttotal: 4m 34s\tremaining: 3m 32s\n",
      "169:\tlearn: 1.1221166\ttest: 1.1335290\tbest: 1.1335290 (169)\ttotal: 4m 35s\tremaining: 3m 30s\n",
      "170:\tlearn: 1.1214144\ttest: 1.1329122\tbest: 1.1329122 (170)\ttotal: 4m 37s\tremaining: 3m 29s\n",
      "171:\tlearn: 1.1209569\ttest: 1.1325284\tbest: 1.1325284 (171)\ttotal: 4m 39s\tremaining: 3m 27s\n",
      "172:\tlearn: 1.1206718\ttest: 1.1323279\tbest: 1.1323279 (172)\ttotal: 4m 40s\tremaining: 3m 25s\n",
      "173:\tlearn: 1.1201128\ttest: 1.1318251\tbest: 1.1318251 (173)\ttotal: 4m 42s\tremaining: 3m 24s\n",
      "174:\tlearn: 1.1198884\ttest: 1.1316541\tbest: 1.1316541 (174)\ttotal: 4m 43s\tremaining: 3m 22s\n",
      "175:\tlearn: 1.1197314\ttest: 1.1315576\tbest: 1.1315576 (175)\ttotal: 4m 45s\tremaining: 3m 20s\n",
      "176:\tlearn: 1.1193537\ttest: 1.1311146\tbest: 1.1311146 (176)\ttotal: 4m 46s\tremaining: 3m 19s\n",
      "177:\tlearn: 1.1191732\ttest: 1.1309966\tbest: 1.1309966 (177)\ttotal: 4m 48s\tremaining: 3m 17s\n",
      "178:\tlearn: 1.1188352\ttest: 1.1306934\tbest: 1.1306934 (178)\ttotal: 4m 49s\tremaining: 3m 15s\n",
      "179:\tlearn: 1.1185096\ttest: 1.1303834\tbest: 1.1303834 (179)\ttotal: 4m 51s\tremaining: 3m 14s\n",
      "180:\tlearn: 1.1179136\ttest: 1.1299285\tbest: 1.1299285 (180)\ttotal: 4m 53s\tremaining: 3m 12s\n",
      "181:\tlearn: 1.1177596\ttest: 1.1298365\tbest: 1.1298365 (181)\ttotal: 4m 54s\tremaining: 3m 11s\n",
      "182:\tlearn: 1.1171229\ttest: 1.1292852\tbest: 1.1292852 (182)\ttotal: 4m 56s\tremaining: 3m 9s\n",
      "183:\tlearn: 1.1167445\ttest: 1.1289733\tbest: 1.1289733 (183)\ttotal: 4m 57s\tremaining: 3m 7s\n",
      "184:\tlearn: 1.1165075\ttest: 1.1287458\tbest: 1.1287458 (184)\ttotal: 4m 59s\tremaining: 3m 6s\n",
      "185:\tlearn: 1.1158582\ttest: 1.1281937\tbest: 1.1281937 (185)\ttotal: 5m 1s\tremaining: 3m 4s\n",
      "186:\tlearn: 1.1155875\ttest: 1.1279274\tbest: 1.1279274 (186)\ttotal: 5m 2s\tremaining: 3m 3s\n",
      "187:\tlearn: 1.1148971\ttest: 1.1272234\tbest: 1.1272234 (187)\ttotal: 5m 4s\tremaining: 3m 1s\n",
      "188:\tlearn: 1.1142331\ttest: 1.1266885\tbest: 1.1266885 (188)\ttotal: 5m 5s\tremaining: 2m 59s\n",
      "189:\tlearn: 1.1137512\ttest: 1.1264239\tbest: 1.1264239 (189)\ttotal: 5m 7s\tremaining: 2m 58s\n",
      "190:\tlearn: 1.1135527\ttest: 1.1262375\tbest: 1.1262375 (190)\ttotal: 5m 9s\tremaining: 2m 56s\n",
      "191:\tlearn: 1.1131952\ttest: 1.1259686\tbest: 1.1259686 (191)\ttotal: 5m 11s\tremaining: 2m 55s\n",
      "192:\tlearn: 1.1128149\ttest: 1.1257766\tbest: 1.1257766 (192)\ttotal: 5m 13s\tremaining: 2m 53s\n",
      "193:\tlearn: 1.1125159\ttest: 1.1255209\tbest: 1.1255209 (193)\ttotal: 5m 14s\tremaining: 2m 51s\n",
      "194:\tlearn: 1.1122745\ttest: 1.1253360\tbest: 1.1253360 (194)\ttotal: 5m 16s\tremaining: 2m 50s\n",
      "195:\tlearn: 1.1117332\ttest: 1.1247128\tbest: 1.1247128 (195)\ttotal: 5m 17s\tremaining: 2m 48s\n",
      "196:\tlearn: 1.1114773\ttest: 1.1245356\tbest: 1.1245356 (196)\ttotal: 5m 19s\tremaining: 2m 46s\n",
      "197:\tlearn: 1.1111400\ttest: 1.1242556\tbest: 1.1242556 (197)\ttotal: 5m 20s\tremaining: 2m 45s\n",
      "198:\tlearn: 1.1102244\ttest: 1.1233275\tbest: 1.1233275 (198)\ttotal: 5m 22s\tremaining: 2m 43s\n",
      "199:\tlearn: 1.1097142\ttest: 1.1229024\tbest: 1.1229024 (199)\ttotal: 5m 24s\tremaining: 2m 42s\n",
      "200:\tlearn: 1.1095448\ttest: 1.1227319\tbest: 1.1227319 (200)\ttotal: 5m 25s\tremaining: 2m 40s\n",
      "201:\tlearn: 1.1089607\ttest: 1.1220814\tbest: 1.1220814 (201)\ttotal: 5m 27s\tremaining: 2m 38s\n",
      "202:\tlearn: 1.1084849\ttest: 1.1215864\tbest: 1.1215864 (202)\ttotal: 5m 29s\tremaining: 2m 37s\n",
      "203:\tlearn: 1.1079608\ttest: 1.1211747\tbest: 1.1211747 (203)\ttotal: 5m 31s\tremaining: 2m 35s\n",
      "204:\tlearn: 1.1078449\ttest: 1.1211162\tbest: 1.1211162 (204)\ttotal: 5m 33s\tremaining: 2m 34s\n",
      "205:\tlearn: 1.1076458\ttest: 1.1210100\tbest: 1.1210100 (205)\ttotal: 5m 34s\tremaining: 2m 32s\n",
      "206:\tlearn: 1.1071367\ttest: 1.1204198\tbest: 1.1204198 (206)\ttotal: 5m 36s\tremaining: 2m 30s\n",
      "207:\tlearn: 1.1068731\ttest: 1.1201948\tbest: 1.1201948 (207)\ttotal: 5m 37s\tremaining: 2m 29s\n",
      "208:\tlearn: 1.1063839\ttest: 1.1196115\tbest: 1.1196115 (208)\ttotal: 5m 39s\tremaining: 2m 27s\n",
      "209:\tlearn: 1.1060546\ttest: 1.1192675\tbest: 1.1192675 (209)\ttotal: 5m 41s\tremaining: 2m 26s\n",
      "210:\tlearn: 1.1057023\ttest: 1.1189032\tbest: 1.1189032 (210)\ttotal: 5m 42s\tremaining: 2m 24s\n",
      "211:\tlearn: 1.1051839\ttest: 1.1183054\tbest: 1.1183054 (211)\ttotal: 5m 45s\tremaining: 2m 23s\n",
      "212:\tlearn: 1.1043863\ttest: 1.1175575\tbest: 1.1175575 (212)\ttotal: 5m 47s\tremaining: 2m 21s\n",
      "213:\tlearn: 1.1039983\ttest: 1.1172390\tbest: 1.1172390 (213)\ttotal: 5m 49s\tremaining: 2m 20s\n",
      "214:\tlearn: 1.1033976\ttest: 1.1166452\tbest: 1.1166452 (214)\ttotal: 5m 52s\tremaining: 2m 19s\n",
      "215:\tlearn: 1.1032028\ttest: 1.1164961\tbest: 1.1164961 (215)\ttotal: 5m 54s\tremaining: 2m 17s\n",
      "216:\tlearn: 1.1030026\ttest: 1.1163933\tbest: 1.1163933 (216)\ttotal: 5m 57s\tremaining: 2m 16s\n",
      "217:\tlearn: 1.1026499\ttest: 1.1161188\tbest: 1.1161188 (217)\ttotal: 5m 59s\tremaining: 2m 15s\n",
      "218:\tlearn: 1.1021554\ttest: 1.1156680\tbest: 1.1156680 (218)\ttotal: 6m 1s\tremaining: 2m 13s\n",
      "219:\tlearn: 1.1019862\ttest: 1.1154848\tbest: 1.1154848 (219)\ttotal: 6m 3s\tremaining: 2m 12s\n",
      "220:\tlearn: 1.1011933\ttest: 1.1147278\tbest: 1.1147278 (220)\ttotal: 6m 6s\tremaining: 2m 10s\n",
      "221:\tlearn: 1.1009828\ttest: 1.1145555\tbest: 1.1145555 (221)\ttotal: 6m 8s\tremaining: 2m 9s\n",
      "222:\tlearn: 1.1007013\ttest: 1.1143361\tbest: 1.1143361 (222)\ttotal: 6m 10s\tremaining: 2m 8s\n",
      "223:\tlearn: 1.1003059\ttest: 1.1140593\tbest: 1.1140593 (223)\ttotal: 6m 13s\tremaining: 2m 6s\n",
      "224:\tlearn: 1.0997885\ttest: 1.1135565\tbest: 1.1135565 (224)\ttotal: 6m 16s\tremaining: 2m 5s\n",
      "225:\tlearn: 1.0995770\ttest: 1.1134584\tbest: 1.1134584 (225)\ttotal: 6m 18s\tremaining: 2m 3s\n",
      "226:\tlearn: 1.0993703\ttest: 1.1133014\tbest: 1.1133014 (226)\ttotal: 6m 19s\tremaining: 2m 2s\n",
      "227:\tlearn: 1.0991429\ttest: 1.1131240\tbest: 1.1131240 (227)\ttotal: 6m 21s\tremaining: 2m\n",
      "228:\tlearn: 1.0988440\ttest: 1.1129304\tbest: 1.1129304 (228)\ttotal: 6m 23s\tremaining: 1m 58s\n",
      "229:\tlearn: 1.0983785\ttest: 1.1124934\tbest: 1.1124934 (229)\ttotal: 6m 25s\tremaining: 1m 57s\n",
      "230:\tlearn: 1.0980520\ttest: 1.1121428\tbest: 1.1121428 (230)\ttotal: 6m 27s\tremaining: 1m 55s\n",
      "231:\tlearn: 1.0977602\ttest: 1.1119311\tbest: 1.1119311 (231)\ttotal: 6m 29s\tremaining: 1m 54s\n",
      "232:\tlearn: 1.0973666\ttest: 1.1116637\tbest: 1.1116637 (232)\ttotal: 6m 32s\tremaining: 1m 52s\n",
      "233:\tlearn: 1.0971874\ttest: 1.1115054\tbest: 1.1115054 (233)\ttotal: 6m 35s\tremaining: 1m 51s\n",
      "234:\tlearn: 1.0969663\ttest: 1.1113650\tbest: 1.1113650 (234)\ttotal: 6m 37s\tremaining: 1m 50s\n",
      "235:\tlearn: 1.0965693\ttest: 1.1110055\tbest: 1.1110055 (235)\ttotal: 6m 39s\tremaining: 1m 48s\n",
      "236:\tlearn: 1.0962239\ttest: 1.1107684\tbest: 1.1107684 (236)\ttotal: 6m 41s\tremaining: 1m 46s\n",
      "237:\tlearn: 1.0958167\ttest: 1.1104491\tbest: 1.1104491 (237)\ttotal: 6m 43s\tremaining: 1m 44s\n",
      "238:\tlearn: 1.0954568\ttest: 1.1101907\tbest: 1.1101907 (238)\ttotal: 6m 45s\tremaining: 1m 43s\n",
      "239:\tlearn: 1.0950006\ttest: 1.1097626\tbest: 1.1097626 (239)\ttotal: 6m 46s\tremaining: 1m 41s\n",
      "240:\tlearn: 1.0946000\ttest: 1.1094455\tbest: 1.1094455 (240)\ttotal: 6m 48s\tremaining: 1m 40s\n",
      "241:\tlearn: 1.0944136\ttest: 1.1092127\tbest: 1.1092127 (241)\ttotal: 6m 50s\tremaining: 1m 38s\n",
      "242:\tlearn: 1.0940662\ttest: 1.1089272\tbest: 1.1089272 (242)\ttotal: 6m 52s\tremaining: 1m 36s\n",
      "243:\tlearn: 1.0938116\ttest: 1.1086686\tbest: 1.1086686 (243)\ttotal: 6m 54s\tremaining: 1m 35s\n",
      "244:\tlearn: 1.0935602\ttest: 1.1084383\tbest: 1.1084383 (244)\ttotal: 6m 56s\tremaining: 1m 33s\n",
      "245:\tlearn: 1.0934491\ttest: 1.1083311\tbest: 1.1083311 (245)\ttotal: 6m 58s\tremaining: 1m 31s\n",
      "246:\tlearn: 1.0929899\ttest: 1.1078919\tbest: 1.1078919 (246)\ttotal: 7m\tremaining: 1m 30s\n",
      "247:\tlearn: 1.0926643\ttest: 1.1076746\tbest: 1.1076746 (247)\ttotal: 7m 3s\tremaining: 1m 28s\n",
      "248:\tlearn: 1.0924983\ttest: 1.1075444\tbest: 1.1075444 (248)\ttotal: 7m 5s\tremaining: 1m 27s\n",
      "249:\tlearn: 1.0922229\ttest: 1.1072912\tbest: 1.1072912 (249)\ttotal: 7m 7s\tremaining: 1m 25s\n",
      "250:\tlearn: 1.0920078\ttest: 1.1071293\tbest: 1.1071293 (250)\ttotal: 7m 9s\tremaining: 1m 23s\n",
      "251:\tlearn: 1.0917775\ttest: 1.1069860\tbest: 1.1069860 (251)\ttotal: 7m 11s\tremaining: 1m 22s\n",
      "252:\tlearn: 1.0914613\ttest: 1.1067025\tbest: 1.1067025 (252)\ttotal: 7m 12s\tremaining: 1m 20s\n",
      "253:\tlearn: 1.0909168\ttest: 1.1062288\tbest: 1.1062288 (253)\ttotal: 7m 14s\tremaining: 1m 18s\n",
      "254:\tlearn: 1.0907230\ttest: 1.1060894\tbest: 1.1060894 (254)\ttotal: 7m 16s\tremaining: 1m 17s\n",
      "255:\tlearn: 1.0905182\ttest: 1.1059234\tbest: 1.1059234 (255)\ttotal: 7m 18s\tremaining: 1m 15s\n",
      "256:\tlearn: 1.0903586\ttest: 1.1057717\tbest: 1.1057717 (256)\ttotal: 7m 21s\tremaining: 1m 13s\n",
      "257:\tlearn: 1.0900381\ttest: 1.1054857\tbest: 1.1054857 (257)\ttotal: 7m 22s\tremaining: 1m 12s\n",
      "258:\tlearn: 1.0896778\ttest: 1.1050794\tbest: 1.1050794 (258)\ttotal: 7m 25s\tremaining: 1m 10s\n",
      "259:\tlearn: 1.0893600\ttest: 1.1047589\tbest: 1.1047589 (259)\ttotal: 7m 27s\tremaining: 1m 8s\n",
      "260:\tlearn: 1.0891411\ttest: 1.1045641\tbest: 1.1045641 (260)\ttotal: 7m 29s\tremaining: 1m 7s\n",
      "261:\tlearn: 1.0888383\ttest: 1.1043399\tbest: 1.1043399 (261)\ttotal: 7m 30s\tremaining: 1m 5s\n",
      "262:\tlearn: 1.0887269\ttest: 1.1042612\tbest: 1.1042612 (262)\ttotal: 7m 32s\tremaining: 1m 3s\n",
      "263:\tlearn: 1.0884710\ttest: 1.1040247\tbest: 1.1040247 (263)\ttotal: 7m 34s\tremaining: 1m 2s\n",
      "264:\tlearn: 1.0883394\ttest: 1.1039595\tbest: 1.1039595 (264)\ttotal: 7m 36s\tremaining: 1m\n",
      "265:\tlearn: 1.0880193\ttest: 1.1036793\tbest: 1.1036793 (265)\ttotal: 7m 38s\tremaining: 58.6s\n",
      "266:\tlearn: 1.0876971\ttest: 1.1034414\tbest: 1.1034414 (266)\ttotal: 7m 40s\tremaining: 56.9s\n",
      "267:\tlearn: 1.0875187\ttest: 1.1032711\tbest: 1.1032711 (267)\ttotal: 7m 41s\tremaining: 55.1s\n",
      "268:\tlearn: 1.0872978\ttest: 1.1032193\tbest: 1.1032193 (268)\ttotal: 7m 43s\tremaining: 53.4s\n",
      "269:\tlearn: 1.0870021\ttest: 1.1030261\tbest: 1.1030261 (269)\ttotal: 7m 45s\tremaining: 51.7s\n",
      "270:\tlearn: 1.0868139\ttest: 1.1028928\tbest: 1.1028928 (270)\ttotal: 7m 47s\tremaining: 50s\n",
      "271:\tlearn: 1.0865287\ttest: 1.1025708\tbest: 1.1025708 (271)\ttotal: 7m 49s\tremaining: 48.3s\n",
      "272:\tlearn: 1.0860053\ttest: 1.1020845\tbest: 1.1020845 (272)\ttotal: 7m 51s\tremaining: 46.6s\n",
      "273:\tlearn: 1.0857551\ttest: 1.1019105\tbest: 1.1019105 (273)\ttotal: 7m 53s\tremaining: 44.9s\n",
      "274:\tlearn: 1.0854011\ttest: 1.1016413\tbest: 1.1016413 (274)\ttotal: 7m 55s\tremaining: 43.2s\n",
      "275:\tlearn: 1.0849119\ttest: 1.1012102\tbest: 1.1012102 (275)\ttotal: 7m 56s\tremaining: 41.5s\n",
      "276:\tlearn: 1.0847374\ttest: 1.1010656\tbest: 1.1010656 (276)\ttotal: 7m 58s\tremaining: 39.8s\n",
      "277:\tlearn: 1.0846044\ttest: 1.1009162\tbest: 1.1009162 (277)\ttotal: 8m\tremaining: 38s\n",
      "278:\tlearn: 1.0845156\ttest: 1.1008560\tbest: 1.1008560 (278)\ttotal: 8m 2s\tremaining: 36.3s\n",
      "279:\tlearn: 1.0843789\ttest: 1.1007748\tbest: 1.1007748 (279)\ttotal: 8m 4s\tremaining: 34.6s\n",
      "280:\tlearn: 1.0841051\ttest: 1.1005445\tbest: 1.1005445 (280)\ttotal: 8m 6s\tremaining: 32.9s\n",
      "281:\tlearn: 1.0840006\ttest: 1.1004738\tbest: 1.1004738 (281)\ttotal: 8m 7s\tremaining: 31.1s\n",
      "282:\tlearn: 1.0838793\ttest: 1.1003733\tbest: 1.1003733 (282)\ttotal: 8m 9s\tremaining: 29.4s\n",
      "283:\tlearn: 1.0837912\ttest: 1.1003132\tbest: 1.1003132 (283)\ttotal: 8m 10s\tremaining: 27.7s\n",
      "284:\tlearn: 1.0836411\ttest: 1.1001719\tbest: 1.1001719 (284)\ttotal: 8m 12s\tremaining: 25.9s\n",
      "285:\tlearn: 1.0833335\ttest: 1.0999623\tbest: 1.0999623 (285)\ttotal: 8m 14s\tremaining: 24.2s\n",
      "286:\tlearn: 1.0831258\ttest: 1.0997912\tbest: 1.0997912 (286)\ttotal: 8m 15s\tremaining: 22.5s\n",
      "287:\tlearn: 1.0830849\ttest: 1.0997803\tbest: 1.0997803 (287)\ttotal: 8m 17s\tremaining: 20.7s\n",
      "288:\tlearn: 1.0828180\ttest: 1.0995633\tbest: 1.0995633 (288)\ttotal: 8m 18s\tremaining: 19s\n",
      "289:\tlearn: 1.0826946\ttest: 1.0994931\tbest: 1.0994931 (289)\ttotal: 8m 20s\tremaining: 17.2s\n",
      "290:\tlearn: 1.0825689\ttest: 1.0993671\tbest: 1.0993671 (290)\ttotal: 8m 21s\tremaining: 15.5s\n",
      "291:\tlearn: 1.0824194\ttest: 1.0992645\tbest: 1.0992645 (291)\ttotal: 8m 22s\tremaining: 13.8s\n",
      "292:\tlearn: 1.0819495\ttest: 1.0988303\tbest: 1.0988303 (292)\ttotal: 8m 24s\tremaining: 12.1s\n",
      "293:\tlearn: 1.0816503\ttest: 1.0986061\tbest: 1.0986061 (293)\ttotal: 8m 26s\tremaining: 10.3s\n",
      "294:\tlearn: 1.0814193\ttest: 1.0983904\tbest: 1.0983904 (294)\ttotal: 8m 28s\tremaining: 8.61s\n",
      "295:\tlearn: 1.0812474\ttest: 1.0982386\tbest: 1.0982386 (295)\ttotal: 8m 29s\tremaining: 6.89s\n",
      "296:\tlearn: 1.0808454\ttest: 1.0977853\tbest: 1.0977853 (296)\ttotal: 8m 31s\tremaining: 5.17s\n",
      "297:\tlearn: 1.0806370\ttest: 1.0975968\tbest: 1.0975968 (297)\ttotal: 8m 32s\tremaining: 3.44s\n",
      "298:\tlearn: 1.0804853\ttest: 1.0974933\tbest: 1.0974933 (298)\ttotal: 8m 34s\tremaining: 1.72s\n",
      "299:\tlearn: 1.0801794\ttest: 1.0971961\tbest: 1.0971961 (299)\ttotal: 8m 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.097196071\n",
      "bestIteration = 299\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2d0877340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_X, train_y, cat_features=cat_features_index, eval_set=(val_X, val_y), plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unitDisplayType: 37.39598405058714\n",
      "countryCode_5: 9.16535646584781\n",
      "deviceId_counts: 9.050600664486833\n",
      "sentPrice: 8.132026844253845\n",
      "countryCode_4: 6.990656903989932\n",
      "countryCode_6: 5.164439576178308\n",
      "countryCode_7: 2.9516745145608203\n",
      "c1: 2.502502196359139\n",
      "countryCode_3: 2.3101203734371145\n",
      "bundleId_encoded: 2.2488884335224877\n",
      "brandName_freq: 2.094723885323548\n",
      "osAndVersion: 1.741564975527172\n",
      "countryCode_2: 1.6911571899069346\n",
      "c3: 1.3564184311019913\n",
      "size: 1.1142514632978715\n",
      "day_of_month: 1.0817997557643304\n",
      "mediationProviderVersion: 0.9552976716583967\n",
      "hour: 0.8573974041660122\n",
      "countryCode_1: 0.5414949872104753\n",
      "correctModelName_7: 0.48470644767637566\n",
      "correctModelName_3: 0.42086770263819245\n",
      "connectionType: 0.39379991388076574\n",
      "correctModelName_2: 0.29962772880006383\n",
      "correctModelName_5: 0.281578304758964\n",
      "correctModelName_0: 0.2124590084332821\n",
      "correctModelName_4: 0.19866251759941148\n",
      "correctModelName_1: 0.18528740157879905\n",
      "correctModelName_6: 0.17665518745386297\n"
     ]
    }
   ],
   "source": [
    "feature_importance = model.get_feature_importance()\n",
    "# Create a dictionary to map feature names to their importance values\n",
    "feature_importance_dict = {feature_name: importance for feature_name, importance in zip(model.feature_names_, feature_importance)}\n",
    "\n",
    "# Sort feature importance by importance value in descending order\n",
    "sorted_importance_dict = dict(sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Print feature importance in descending order\n",
    "for feature_name, importance in sorted_importance_dict.items():\n",
    "    print(f'{feature_name}: {importance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29, 1.12, 0.08, ..., 0.4 , 0.18, 0.39])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = val_y.to_numpy()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07369419, 0.20807517, 0.16162359, ..., 0.30785617, 0.14010312,\n",
       "       0.31048028])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(val_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsme_by_percentiles(y_true: np.array, y_pred: np.array) -> pd.DataFrame:\n",
    "    # Let's define percentiles\n",
    "    percentiles = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
    "\n",
    "    # create a dataframe from predictions and actual values\n",
    "    df_eval = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "\n",
    "    # Calculate percentiles on actual values\n",
    "    df_eval['percentile'] = pd.qcut(df_eval['y_true'], q=percentiles, labels=False)\n",
    "\n",
    "    # Calculate RMSE for each percentile\n",
    "    rmse_values = df_eval.groupby('percentile').apply(lambda group: np.sqrt(mean_squared_error(group['y_true'], group['y_pred'])))\n",
    "\n",
    "    # Creating DataFrame to store all the information\n",
    "    percentile_data = pd.DataFrame(index=range(len(percentiles)-1))\n",
    "\n",
    "    # Calculate min, max and mean for each percentile\n",
    "    percentile_data['min_value'] = df_eval.groupby('percentile')['y_true'].min()\n",
    "    percentile_data['max_value'] = df_eval.groupby('percentile')['y_true'].max()\n",
    "    percentile_data['mean_value'] = df_eval.groupby('percentile')['y_true'].mean()\n",
    "\n",
    "    # Add RMSE\n",
    "    percentile_data['rmse'] = rmse_values\n",
    "    return percentile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Root Mean Squared Error (RMSE):', 1.0971960714167488)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Root Mean Squared Error (RMSE):', np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.019756</td>\n",
       "      <td>0.264237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.057175</td>\n",
       "      <td>0.237794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.091782</td>\n",
       "      <td>0.246888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.184817</td>\n",
       "      <td>0.342262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.335894</td>\n",
       "      <td>0.430798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.582791</td>\n",
       "      <td>0.549747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.630592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.08</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.298860</td>\n",
       "      <td>0.741441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.64</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.326411</td>\n",
       "      <td>1.345758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.53</td>\n",
       "      <td>15.92</td>\n",
       "      <td>7.957463</td>\n",
       "      <td>2.917514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_value  max_value  mean_value      rmse\n",
       "0       0.01       0.03    0.019756  0.264237\n",
       "1       0.04       0.07    0.057175  0.237794\n",
       "2       0.08       0.12    0.091782  0.246888\n",
       "3       0.13       0.25    0.184817  0.342262\n",
       "4       0.26       0.45    0.335894  0.430798\n",
       "5       0.46       0.74    0.582791  0.549747\n",
       "6       0.75       1.07    0.898974  0.630592\n",
       "7       1.08       1.63    1.298860  0.741441\n",
       "8       1.64       3.52    2.326411  1.345758\n",
       "9       3.53      15.92    7.957463  2.917514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rsme_by_percentiles(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = pd.read_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep(df=train_data_all, p=0, is_train=False)\n",
    "df = feature_engineering(df, train_encoders=train_encoders, train_top_values=train_top_values, most_frequent_category=most_frequent_category)\n",
    "\n",
    "y_true = df['winBid'].to_numpy()\n",
    "\n",
    "X = df.drop(['winBid', \n",
    "            'has_won'\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7321633,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7321633,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Root Mean Squared Error (RMSE):', 19.509501629119267)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Root Mean Squared Error (RMSE):', np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>mean_value</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>0.265465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.065204</td>\n",
       "      <td>0.229623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.108197</td>\n",
       "      <td>0.309213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.212704</td>\n",
       "      <td>0.354519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.390939</td>\n",
       "      <td>0.515496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.674398</td>\n",
       "      <td>0.586301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.019820</td>\n",
       "      <td>0.687266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.22</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.581981</td>\n",
       "      <td>0.893938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.07</td>\n",
       "      <td>6.94</td>\n",
       "      <td>3.686935</td>\n",
       "      <td>2.040373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.95</td>\n",
       "      <td>3405.72</td>\n",
       "      <td>34.185956</td>\n",
       "      <td>61.669538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_value  max_value  mean_value       rmse\n",
       "0       0.01       0.03    0.019761   0.265465\n",
       "1       0.04       0.08    0.065204   0.229623\n",
       "2       0.09       0.14    0.108197   0.309213\n",
       "3       0.15       0.29    0.212704   0.354519\n",
       "4       0.30       0.51    0.390939   0.515496\n",
       "5       0.52       0.84    0.674398   0.586301\n",
       "6       0.85       1.21    1.019820   0.687266\n",
       "7       1.22       2.06    1.581981   0.893938\n",
       "8       2.07       6.94    3.686935   2.040373\n",
       "9       6.95    3405.72   34.185956  61.669538"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rsme_by_percentiles(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Test Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/test_data.csv')\n",
    "device_id_test = test_data['deviceId'].copy()\n",
    "df = data_prep(df=test_data, is_train=False)\n",
    "df = feature_engineering(df, train_encoders=train_encoders, train_top_values=train_top_values, most_frequent_category=most_frequent_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(df)\n",
    "result_df = pd.DataFrame({\n",
    "    'deviceID': device_id_test,\n",
    "    'winBid': test_preds\n",
    "})\n",
    "\n",
    "result_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
